LLM setup

uv tool install llm

llm install llm-openrouter llm-claude-3 llm-ollama llm-llamafile llm-gemini llm-perplexity llm-groq llm-grok llm-palm llm-bedrock-meta llm-bedrock-anthropic  llm-jq llm-cluster  llm-jq llm-python llm-cmd llm-embed-onnx llm-llamafile llm-model-gateway


takes a long time: llm-gguf about 5 mins
consider for macos: https://github.com/simonw/llm-mlc

also consider https://venice.ai/chat https://github.com/ar-jan/llm-venice

run: llm keys set <your-vendor>

llm models default claude-3.5-sonnet-latest


llm 'Ten names for cheesecakes'
Here are ten creative names for cheesecakes:

1. Classic New York-Style Cheesecake
2. Heavenly Vanilla Bean Dream
3. Triple Chocolate Decadence
4. Berry Bliss Swirl
5. Caramel Pecan Paradise
6. Cookies & Cream Delight
7. Lemon Zest Supreme
8. White Chocolate Raspberry Symphony
9. Turtle Temptation
10. Pumpkin Spice Sensation


PS C:\Users\shane\AppData\Roaming\uv\tools> llm models --help
Usage: llm models [OPTIONS] COMMAND [ARGS]...

  Manage available models

Options:
  --help  Show this message and exit.

Commands:
  list*    List available models
  default  Show or set the default model
PS C:\Users\shane\AppData\Roaming\uv\tools>



broken: llm-embed-jina llm-sentence-transformers

llm embed-model


uv tool install paginate-json

paginate-json 'https://api.github.com/repos/simonw/llm/issues?state=all&filter=all' `
  | jq '[.[] | {id: .id, title: .title}]' `
  | llm embed-multi llm-issues - `
    --database llm-issues.db `
    --model onnx-bge-large `
    --store


llm cluster llm-issues 10 `
  -d llm-issues.db

llm cluster llm-issues 10 `
  -d llm-issues.db `
  --summary

llm cluster llm-issues 2 `
  -d llm-issues.db `
  --summary `
  --prompt 'Summarize this in a short line in the style of a bored, angry panda'


PS C:\Users\shane\AppData\Roaming\uv\tools> llm --help
Usage: llm [OPTIONS] COMMAND [ARGS]...

  Access Large Language Models from the command-line

  Documentation: https://llm.datasette.io/

  LLM can run models from many different providers. Consult the plugin
  directory for a list of available models:

  https://llm.datasette.io/en/stable/plugins/directory.html

  To get started with OpenAI, obtain an API key from them and:

      $ llm keys set openai
      Enter key: ...

  Then execute a prompt like this:

      llm 'Five outrageous names for a pet pelican'

Options:
  --version  Show the version and exit.
  --help     Show this message and exit.

Commands:
  prompt*       Execute a prompt
  aliases       Manage model aliases
  chat          Hold an ongoing chat with a model.
  cluster       Generate clusters from embeddings in a collection
  cmd           Generate and execute commands in your shell
  collections   View and manage collections of embeddings
  embed         Embed text and store or return the result
  embed-models  Manage available embedding models
  embed-multi   Store embeddings for multiple strings at once
  grok          Commands for the Grok model
  install       Install packages from PyPI into the same environment as LLM
  jq            Pipe JSON data into this tool and provide a description...
  keys          Manage stored API keys for different models
  logs          Tools for exploring logged prompts and responses
  models        Manage available models
  ollama        Commands for working with models hosted on Ollama
  openai        Commands for working directly with the OpenAI API
  palm          Commands for working directly with PaLM
  plugins       List installed plugins
  python        Run Python interpreter, passing through any arguments
  similar       Return top N similar IDs from a collection
  templates     Manage stored prompt templates
  uninstall     Uninstall Python packages from the LLM environment